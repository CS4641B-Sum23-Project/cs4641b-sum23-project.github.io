<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8" />
    <title>Penguins vs Turtles</title>
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css"
      rel="stylesheet"
      integrity="sha384-9ndCyUaIbzAi2FUVXJi0CjmCapSmO7SnpJef0486qhLnuZ2cdeRhO02iuK6FUUVM"
      crossorigin="anonymous"
    />
    <link rel="stylesheet" href="assets/css/style.css" />
  </head>
  <body>
    <div id="content">
      <article>
        <div class="col-md-3 col-sm-12">
          <h1 class="page-header">Penguins vs Turtles</h1>
        </div>

        <div class="container">
          <div class="row" class="col-md-12"></div>
            <div class="col-md-2 col-sm-0"></div>
            <div class="col-md-3 col-sm-12"> 
              <h1 class="page-header"></h1>
            </div>
        </div>
<br>
<br>
<br>
        <div class="jumbotron jumbotron-fluid">
          <div class="container" style="background: #ffff">
              <div class="mt-0">
                <h2>Infographic</h2>
                <div style='border-bottom:3px solid lightgrey;'></div>
              </div>
              <div style="margin-top: 10px; padding: 20px;">
                <!-- <img src="assets/images/me.jpeg" class="col-md-3 col-sm-12 img-fluid"> -->
                <img src="assets/images/infographic_v2.png">
              </div>
            </div>
          </div>
        

        <div class="jumbotron jumbotron-fluid">
          <div class="container" style="background: #ffff">
            <div class="mt-0">
              <h2>Introduction</h2>
              <div style="border-bottom: 3px solid lightgrey"></div>
            </div>
            <div style="margin-top: 10px; padding: 20px">
              <!-- <img src="assets/images/me.jpeg" class="col-md-3 col-sm-12 img-fluid"> -->
              <p>
                Given three distinct types of images; penguins, turtles, and
                strictly images that are landscapes. We wish to develop an
                algorithm that can distinguish between these three types of
                images. Currently, classification of images is most successful
                when utilizing Deep Learning, or Convolutional Neural Networks
                (CNN) as these models can identify meaningful transformations of
                images for us, rather than hand crafting these transformations
                from the images. Despite these models having remarkable success
                with images where the target is the singular subject, they tend
                to still have difficulties correctly classifying an image if the
                image has a lot of “clutter” or “noise” and can often fall short
                if there are not enough datapoints for the model to work with.
              </p>
            </div>
          </div>
        
        <div class="jumbotron jumbotron-fluid">
          <div class="container" style="background: #ffff">
              <div class="mt-0">
                <h2>Methodology</h2>
                <div style='border-bottom:3px solid lightgrey;'></div>
              </div>
              <div style="margin-top: 10px; padding: 20px;">
                <!-- <img src="assets/images/me.jpeg" class="col-md-3 col-sm-12 img-fluid"> -->
                <p>
                  Our data currently consists of 857 unique images. 749 of these images are used to train the machine learning model,
                  while the rest of the images are reserved for evaluating the trained model’s performance. Our dataset uses discrete 
                  categories to describe the target values, where 1 represents a penguin, 2 represents a turtle, and 3 represents 
                  the background.
                </p>
                <p> 
                  To clean up and standardize our images we used the provided bounding boxes to reduce the image size. We reduced image size even further for specific purposes, e.g. clustering using   
                  KMeans and training our CNN, by scaling our images to 256x256 and 64x64 pixels when necessary.
                  In doing so, we reduced noise, improved computational efficiency, and removed outliers.  
                  Each image was then placed into a dataframe where they could be further played with 
                  with functions we develpoed. These fucntions include: conversion and extraction of the bounding box, finding and applying contours, resizing, applying 
                  greyscale and preprocessing. Additionally, we may note that the finalized images were placed into a pkl file for ease of access and to 
                  reduce computation time.
                </p>
                <p>
                  We tested several algorithms for feature extraction such as Canny Edge detection, Histogram of Gradients, MobileNetV2 and ORB. Canny Edge Detection was specifically employed to detect edges of the turtle or penguin in the given image. Histogram of Gradients calculated the distribution of gradients within the image, generating a histogram based on the gradient values. Among these algorithms, the MobileNetV2 gave the best results. On the other hand, the algorithm that gave us the worst results was the Oriented FAST and Rotated BRIEF(ORB), which is a combination of the FAST corner detector and the BRIEF descriptor. ORB detected key points and features in an image based on local intensity, subsequently computing binary descriptors to represent those features. To further reduce dimensionality and perform feature selection, we used PCA and Kernel PCA.
                </p>
                <p>
                  Although CNN literature gave us promising outlook at the start, our current classifier’s result is quite underwhelming. Since our task of separating three different classes of images have been done numerous times, we decided to use pre-trained model after researching about our goal. There were several excellent choices, promising accuracy of at least 92%; the top contenders being a Sequential TensorFlow Keras model and a ResNet model. Simplicity is key, so we first adopted the Sequential model.

Adam optimizer is widely used in Deep Learning. Since it is an extension of stochastic gradient descent, it is excellent in helping us avoid getting stuck on local minima. For the compile function’s metrics, we use accuracy, which will allow Keras to choose the best accuracy function for us. Below is a summary of our CNN model.Although CNN literature gave us promising outlook at the start, our current classifier’s result is quite underwhelming. Since our task of 
                  separating three different classes of images have been done numerous times, we decided to use pre-trained model after researching about our goal. 
                  There were several excellent choices, promising accuracy of at least 92%; the top contenders being a Sequential TensorFlow Keras model and a 
                  ResNet model. Simplicity is key, so we first adopted the Sequential model.
                </p>
                <p>
                  Adam optimizer is widely used in Deep Learning. Since it is an extension of stochastic gradient descent, it is excellent in helping us avoid 
                  getting stuck on local minima. For the compile function’s metrics, we use accuracy, which will allow Keras to choose the best accuracy function 
                  for us. Below is a summary of our CNN model.
                </p>
                <img src="assets/images/cnn_model_summary.png">
              </div>
            </div>
        </div>
        <div class="jumbotron jumbotron-fluid">
          <div class="container" style="background: #ffff">
              <div class="mt-0">
                <h2>Results</h2>
                <div style='border-bottom:3px solid lightgrey;'></div>
              </div>
              <div style="margin-top: 10px; padding: 20px;">
                 <figure>
                 <img src="assets/images/Kmeans Centroids/KMeans Centroids.png" style="width: 1000px; height: 600;">
                 <figcaption>
We utilized KMeans to visualize and cluster our normalized pixel values. In the above graph, you can see that there is some overlap between the three clusters, indicating that there will be some confusion using unsupervised learning algorithms to separate our data. Ideally, these clusters would be completely separated. 
                   
                 </figcaption>
                 </figure> 
                 <img src="assets/images/MobileNetV2_Features_PCA.jpg"> 
                 <img src="assets/images/cluster_gmm_edge_pca.jpg"> 
                 <img src="assets/images/cluster_gmm_edge_pca_metrics.jpg"> 
                 <img src="assets/images/cluster_gmm_hog_pca.jpg"> 
                 <img src="assets/images/cluster_gmm_hog_pca_metrics.jpg"> 
                 <img src="assets/images/cluster_gmm_mobilenet_bb_pca.jpg"> 
                 <figure>
                 <img src="assets/images/cluster_gmm_mobilenet_bb_pca_metrics.jpg"> 
                 <figcaption>We were able to get a good separation of the two animals using MobileNetV2, even with reduced dimensions. This method 
                   yields the best result, as reflected in the chart of the evaluation metrics</figcaption>
                </figure>
                 <img src="assets/images/cluster_kmean_edge_pca.jpg"> 
                 <img src="assets/images/cluster_kmean_hog_pca.jpg">
                 <img src="assets/images/cluster_kmean_hog_pca_metrics.jpg"> 
                 <img src="assets/images/cluster_kmean_mobilenet_bb_pca.jpg">
                 <img src="assets/images/cluster_kmean_mobilenet_bb_pca_metrics.jpg">
                <p> 
                  From the accuracy metric, we were able to record our model’s training and validation accuracy, which is reflected in the plot below.
                </p>
                <img src="assets/images/cnn_accuracy.png">
                <img src="assets/images/cnn_loss.png">
                <p>
                  Our classifier is highly volatile in its prediction accuracy, which is hovering around 40%. Further, the loss is too high. 
                  Which means we are making numerous mistakes. This is likely due to several factors:                
                </p>
                <ul>
                  <li>
                    As this is an image classifier, our model will do better with more image data. Five hundred is the minimum, and evidently 
                    it’s very little in practice.
                  </li>
                  <li>
                    The bounding boxes are too big compared to some zoomed out images of the animal.<a href="contact.html">Contact</a>
                  </li>
                  <li>
                    The animals are evolved to blend in with their surrounding for survival. Hence, the confusion between animal and background 
                    image is high. This is reflected in a 2 class classifier between just the penguins and turtle (plot attached below). This model 
                    has much higher and stable accuracy.
                  </li>
                </ul>
                <img src="assets/images/cnn_twoclass_accuracy.png">
                <img src="assets/images/cnn_twoclass_loss.png">
              </div>
            </div>
        </div>
        <div class="jumbotron jumbotron-fluid">
          <div class="container" style="background: #ffff">
              <div class="mt-0">
                <h2>Discussion</h2>
                <div style='border-bottom:3px solid lightgrey;'></div>
              </div>
              <div style="margin-top: 10px; padding: 20px;">
                <p>
                  By resizing the images and strictly analyzing the background color, we were able to improve the differentiation
                  between images of turtles and penguins. When using edge detection, which helped represent features like the beaks, 
                  fins, and shells in the provided image did work so well as you can see in the above image. This suggested that the 
                  features between penguins and turtles might be too like rely solely on edge. Using Histogram of Gradients, we 
                  discovered penguins exhibit more uniform and gradual changes in gradients, while turtles had a more varied and 
                  complex gradient. Despite this information, a clear separation between the two classes was still not apparent. 
                  The most effective approach was the utilization of MobileNetV2 because it automatically distinguished specific 
                  patterns associated with turtles and penguins and used them as features. 
                </p>
                <p>
                  Due to the poor performance of edge detection and gradient distribution we decided to try incorporating these 
                  techniques with other ones like PCA. We also incorporated data augmentation, utilizing techniques such as funneling 
                  our images through a data frame and experimenting with trace breaks in code to explore alternative ideas.
                </p>
                <p>
                  During our unsupervised learning analysis, we used Clustering, K-means, Gaussian mixture Models (GMM), and DBSCAN. 
                  Evaluating the clustering results provided insights into the quality of the clusters. The Silhouette coefficient, which 
                  measures cluster separation, seemed relatively low for all charts, indicating that clusters were overlapping with each 
                  other. The DBI metric supports the presence of overlapping clusters with it being high around 0.85. Looking at the NMI 
                  metric, which quantifies the similarity between predicted clusters and true labels, the score was relatively low. This 
                  suggests that the clusters have a limited similarity and our cluster algorithms struggled to capture underlying patterns 
                  accurately. Finally, Folkes-Mallow, which is used to evaluate the similarities between predicted clusters and true labels, 
                  demonstrated higher scores. Comparing the performance between GMM and K-Means, it seemed like K-Means did much better 
                  with its NMI mostly being larger than all the algorithms except Histogram of Gradients. In summary, our analysis revealed 
                  the challenge of achieving distinct and well separated clusters due to overlapping patterns.
                </p> 
                <p>
                  As stated above in results, when looking at each alogrithm, MobileNetv2 yieled the best result when paired with PCA. 
                  Kmeans, HOG, and Canny Edges provided decent clustering but fall short, and that makes sense as MobileNetV2 is designed
                  to process a more complicated load of imformation. Each of the other three are simpler and lack the ability to recognize 
                  the complexity an image may present. Kmeans and HOG still performed decently with PCA, whereas Canny Edges was just ok as
                  it isn't as directly involved in that process. 
                </p>
                <p>
                  The results for our binary CNN classifier perfromed better than our multilclass with backgrounds. As spoken about, there reasons for this such as 
                  animal adaption and color schemes, however I still think there were errors in adjusting our data correctly which led to our results not yielding a high accuracy. 
                  It is entirely possible we used the worng optimizer or activations or had improper depth on the model. For these reasons CNN was not the best supervised learning method for our team. 
                </p>
              </div>
            </div>
        </div>
        <div class="jumbotron jumbotron-fluid">
          <div class="container" style="background: #ffff">
              <div class="mt-0">
                <h2>References</h2>
                <div style='border-bottom:3px solid lightgrey;'></div>
              </div>
              <div style="margin-top: 10px; padding: 20px;">
                <a href="https://www.kaggle.com/datasets/abbymorgan/penguins-vs-turtles"
                >Kaggle Turtles and Penguins Dataset</a
              >
              <br />
              <a
                href="https://ieeexplore.ieee.org/abstract/document/9132851?casa_token=GeeAyY3ANu0AAAAA:4df-4yo2tQKZr5yTgExPcTzbx4RzWSUkYqooTc7ygn71H5q7BOMXPrhDW9TG9X_Bmg0LgT8unQ"
                >Image Classification using SVM and CNN</a
              >
              <br />
              <a href="https://www.nature.com/articles/s41467-022-27980-y"
                >Perspectives in machine learning for wildlife conservation</a
              >
              </div>
            </div>
        </div>
      </article>
    </div>
    <footer>
      By Blake West, Derrick Yu, Eirene Lakshita, Lauren Fowler, John Binek
    </footer>
  </body>
</html>
